import re  # <--- QUAN TR·ªåNG: Ph·∫£i c√≥ d√≤ng n√†y ƒë·ªÉ x·ª≠ l√Ω Regex
import os
import json
import uvicorn
import google.generativeai as genai
from fastapi import FastAPI, UploadFile, File
from dotenv import load_dotenv
from app.models import NaturalLanguageOrderRequest, DraftOrderResponse, ProductSyncRequest
from app.services.rag_service import rag_service
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from google.api_core import exceptions

# 1. C·∫•u h√¨nh m√¥i tr∆∞·ªùng
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=api_key)

app = FastAPI(title="BizFlow AI Service (Stable)")

# --- C·∫§U H√åNH MODEL ---
# S·ª≠ d·ª•ng model n√†y ƒë·ªÉ ·ªïn ƒë·ªãnh v√† √≠t b·ªã gi·ªõi h·∫°n Quota
GENERATIVE_MODEL_NAME = "gemini-2.5-flash" 

@app.post("/api/products/sync")
async def sync_products(request: ProductSyncRequest):
    data = [p.dict() for p in request.products]
    rag_service.sync_products(request.owner_id, data)
    return {"status": "success", "count": len(data)}

# --- H√ÄM G·ªåI GEMINI AN TO√ÄN (RETRY) ---
@retry(
    retry=retry_if_exception_type(exceptions.ResourceExhausted),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def generate_content_safe(model, prompt):
    return model.generate_content(prompt)

async def parse_order_with_rag(message: str, owner_id: str) -> DraftOrderResponse:
    try:
        # 1. T√¨m ki·∫øm RAG
        relevant_products = rag_service.search_products(owner_id, message)
        
        context_str = ""
        if relevant_products:
            context_str = "DANH S√ÅCH S·∫¢N PH·∫®M TRONG KHO (Tham kh·∫£o):\n"
            for p in relevant_products:
                context_str += f"- T√™n: {p['original_name']} | Gi√°: {p['price']} | ƒê∆°n v·ªã: {p['unit']}\n"
        else:
            context_str = "Kho ch∆∞a c√≥ d·ªØ li·ªáu s·∫£n ph·∫©m t∆∞∆°ng ·ª©ng."

        # 2. G·ªçi Gemini
        model = genai.GenerativeModel(GENERATIVE_MODEL_NAME)
        
        prompt = f"""
        B·∫°n l√† API x·ª≠ l√Ω ƒë∆°n h√†ng. Nhi·ªám v·ª• duy nh·∫•t: Tr·∫£ v·ªÅ JSON.
        
        {context_str}
        
        Y√äU C·∫¶U X·ª¨ L√ù:
        1. N·∫øu t√™n s·∫£n ph·∫©m kh√°ch n√≥i KH·ªöP trong danh s√°ch -> D√πng "product_name" chu·∫©n c·ªßa danh s√°ch.
        2. N·∫øu t√™n s·∫£n ph·∫©m KH√îNG C√ì trong danh s√°ch -> D√πng CH√çNH X√ÅC t√™n kh√°ch n√≥i.
        3. "quantity": S·ªë l∆∞·ª£ng (m·∫∑c ƒë·ªãnh 1).
        4. "unit": ƒê∆°n v·ªã (n·∫øu kh√°ch kh√¥ng n√≥i, ƒë·ªÉ null).
        5. "is_debt": True n·∫øu c√≥ t·ª´ kh√≥a n·ª£, ghi s·ªï.
        6. "customer_name": T√™n kh√°ch (n·∫øu c√≥).

        C√¢u kh√°ch n√≥i: "{message}"
        
        TR·∫¢ V·ªÄ ƒê√öNG ƒê·ªäNH D·∫†NG JSON SAU (Kh√¥ng th√™m l·ªùi d·∫´n):
        {{
            "customer_name": "string | null", 
            "items": [
                {{ "product_name": "string", "quantity": number, "unit": "string" }}
            ],
            "is_debt": boolean, 
            "original_message": "string" 
        }}
        """
        
        # G·ªçi Gemini
        response = generate_content_safe(model, prompt)
        raw_text = response.text.strip()
        print(f"ü§ñ [DEBUG RAW GEMINI]: {raw_text}") 

        # 3. Tr√≠ch xu·∫•t JSON b·∫±ng Regex (Fix l·ªói Markdown)
        json_match = re.search(r'\{.*\}', raw_text, re.DOTALL)
        
        if json_match:
            json_str = json_match.group()
            data = json.loads(json_str)
            data['original_message'] = message
            return DraftOrderResponse(**data)
        else:
            print("‚ùå Kh√¥ng t√¨m th·∫•y JSON trong ph·∫£n h·ªìi")
            raise ValueError("AI response is not JSON")

    except exceptions.ResourceExhausted:
        print("‚ùå H·∫øt Quota Google (429)")
        return DraftOrderResponse(
            customer_name=None, items=[], is_debt=False, original_message=message + " (Server B·∫≠n)"
        )
    except Exception as e:
        print(f"‚ùå L·ªói Parse Logic: {e}")
        return DraftOrderResponse(
            customer_name=None, items=[], is_debt=False, original_message=message
        )

# 4. Endpoints
@app.post("/api/parse-order", response_model=DraftOrderResponse)
async def parse_order(request: NaturalLanguageOrderRequest):
    print(f"üì© Parse Order cho Owner {request.owner_id}: {request.message}")
    result = await parse_order_with_rag(request.message, request.owner_id)
    return result

@app.post("/api/orders/ai/transcribe")
async def transcribe_audio(audio: UploadFile = File(...)):
    try:
        audio_bytes = await audio.read()
        model = genai.GenerativeModel(GENERATIVE_MODEL_NAME)
        
        response = generate_content_safe(model, [
            "Ch√©p l·∫°i n·ªôi dung ƒëo·∫°n ghi √¢m n√†y b·∫±ng ti·∫øng Vi·ªát:",
            {"mime_type": "audio/webm", "data": audio_bytes}
        ])
        
        return {"success": True, "text": response.text.strip()}
    except Exception as e:
        print(f"‚ùå L·ªói Audio: {e}")
        return {"success": False, "message": str(e)}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)